# Análisis de las diferentes plataformas existentes de Machine Learning.

Antes de meternos de lleno a explicar y definir las diferentes plataformas de ML que vamos a usar o implementar en nuestro proyecto con el fin de probar los resultados que esperamos obtener, vamos a realizar una pequeña introducción sobre como se utiliza hoy en día la IA en nuestro día a día.

## Introducción

La inteligencia artificial (IA) es una expresión técnica referida a artefactos empleados para detectar contextos o llevar a cabo acciones en respuesta a contextos detectados. Nuestra capacidad de construir dichos artefactos ha aumentado y, con ello, el impacto que tienen en nuestra sociedad. Podemos hablar de como ha empezado a influir en los cambios sociales y económicos propiciados por nuestro uso, pero no exclusivamente en la década transcurrida desde la aparición de los teléfonos inteligentes (2007), que contribuyen de manera sustancial a los macrodatos y, por tanto, a la eficacia del aprendizaje de las máquinas. En términos generales, la IA no es una tecnología tan inusual como se esperaba, y precisamente por esa razón los desafíos que plantea pueden ser más apremiantes. En concreto, la identidad y la autonomía tanto de individuos como de naciones están amenazadas por el creciente acceso al conocimiento.

En algunos casos podemos hablar de la IA como de una forma de computación y, como tal, de transformación de la información. 

Durante décadas, incluso antes de la creación del término, la IA suscitó tanto miedo como interés, cuando la humanidad contemplaba la posibilidad de crear máquinas a su imagen y semejanza. Los avances de la IA a la hora de superar la capacidad humana en actividades como el ajedrez (Hsu, 2002), el juego del Go (Silver *et al.*, 2016) y la traducción (Wu *et al.*, 2016) llegan ahora a los titulares, pero la IA está presente en la industria desde, al menos, la década de 1980. Por entonces los sistemas de normas de producción o sistemas «expertos» se convirtieron en la tecnología estándar para comprobar circuitos impresos y detectar el fraude con tarjetas de créditos (Liao, 2005). De modo similar, hace tiempo que se emplean estrategias de aprendizaje automático (AA), como los algoritmos genéticos, para problemas computacionales de muy difícil resolución, como la planificación de sistemas operativos informáticos y redes neuronales, para modelizar y comprender el aprendizaje humano, pero también para tareas básicas de control y supervisión básicos en la industria (Widrow *et al.*, 1994). Durante la década de 1990, los métodos probabilísticos y bayesianos revolucionaron el AA y sentaron las bases de algunas de las tecnologías de IA predominantes hoy: por ejemplo, la búsqueda a través de grandes masas de datos (Bishop, 1995). Esta capacidad de búsqueda incluía la posibilidad de hacer análisis semánticos de textos en bruto que permiten a los usuarios de la red encontrar los documentos que buscan entre billones de páginas web con solo escribir unas cuantas palabras (Lowe, 2001; Bullinaria y Levy, 2007).



Esta capacidad de descubrimiento de la IA se ha ampliado no solo por el incremento masivo de los datos digitales y la capacidad de computación, también por las innovaciones en los algoritmos de IA y AA. Hoy buscamos fotografías, vídeos y audio (Barrett *et al.*, 2016; Wu *et al.*, 2016). Podemos traducir, trascribir, leer labios, interpretar emociones (incluidas las mentiras), falsificar firmas y otros tipos de escritura manual y manipular vídeos. 

La IA ya se encuentra presente en nuestro día a día, a nuestra disposición y nos beneficia a todos, podemos mencionar casos tales como en forma de vehículos, armas, drones y dispositivos domésticos autónomos, incluidos los «altavoces inteligentes» e incluso consolas de videojuegos. Cada vez estamos más rodeados —integrados incluso— de percepciones, análisis y (cada vez más) acciones automatizadas generalizadas.

![BBVA-OpenMind-ilustración-Joanna-J-Bryson-ultima-decada-y-el-futuro-del-impacto-IA-en-la-sociedad-Un hombre observa un software que analiza los movimientos humanos en el estand de la compañia de IA Horizon Robotics durante la feria Scurity China, en Pekin, octubre de 2018](https://www.bbvaopenmind.com/wp-content/uploads/2018/12/BBVA-OpenMind-ilustraci%C3%B3n-Joanna-J-Bryson-ultima-decada-y-el-futuro-del-impacto-IA-en-la-sociedad-a.jpg)







## Historia de la inteligencia artificial

**1943-1955: Warren McCulloch y Walter Pitts** (1943) están reconocidos como los **autores del primer trabajo de IA**. Partieron de tres fuentes: conocimientos sobre la fisiología básica y funcionamiento de las neuronas en el cerebro, el análisis formal de la lógica preposicional de Russell y Whitehead y la teoría de la computación de Turing.



![img](https://www.diarioinformacion.com/elementosWeb/gestionCajas/INF/Image/2019//2-inteligencia-artificial-reconocimiento-facial-Microsoft-Google-asistentes--voz-Siri.jpg)



**1956:** En un Congreso sobre Informática Teórica **en EE.UU se define el concepto** de Inteligencia Artificial, como una nueva rama de la informática con entidad propia, proponiéndose como una disciplina que buscaba **reproducir comportamiento inteligente** con la ayuda de una máquina.



**1956-1969:** Periodo de **grandes expectativas** y en el que hubo algunos **éxitos** que marcaron la esperanza del desarrollo de la inteligencia artificial. Entre ellos, **un ordenador podía jugar a las damas** y hacer más cosas que cálculos aritméticos. En 1959, **Herbert Gelernter,** por su lado, construyó una máquina capaz de demostrar de teoremas de geometría.



**1966-1973:** Las previsiones que auguraban un futuro exitoso en IA se topan con la realidad debido a las **dificultades existentes**. En esta época, la mayoría de los primeros programas contaban con poco o ningún conocimiento de la materia objeto de estudio, por lo que se obtenían resultados gracias a sencillas manipulaciones sintácticas. Un ejemplo de esta época fue la **traducción errónea de la frase del ruso al inglés «El espíritu es fuerte pero la carne es débil»**, cuyo resultado fue «El vodka es bueno pero la carne está podrida».



**1980**: **La IA se convierte en ciencia**. En 1982 la empresa McDermott creó el **primer sistema experto comercial llamado R1** el cual utilizaba la elaboración de pedidos informáticos. Cuatro años más tarde R1 representó un ahorro de aproximadamente 40 millones de dólares al año y en 1988 la inteligencia artificial distribuía mas de 40 sistemas expertos.



**1996**: **Deep Blue**, la supercomputadora de IBM, marca un **hito en 1996** al vencer al campeón mundial de ajedrez. Esta computadora era capaz de procesar 200 posiciones en un segundo.



![img](https://www.diarioinformacion.com/elementosWeb/gestionCajas/INF/Image/2019//3-inteligencia-artificial-reconocimiento-facial-Microsoft-Google-asistentes--voz-Siri.jpg)



**2002**: La empresa estadounidense **iRobot creó Roomba, el primer producto comercial exitoso para el uso en el hogar** que utilizaba el principio de inteligencia artificial: la aspiradora autónoma Roomba. Joe Jone, uno de sus creadores, empezó como físico experimental y luego llegó al MIT.



![img](https://www.diarioinformacion.com/elementosWeb/gestionCajas/INF/Image/2019//4-roomba-inteligencia-artificial-reconocimiento-facial-Microsoft-Google-asistentes--voz-Siri.jpg)



**2008**: Las **primeras versiones de BigDog, un robot autónomo que simula a un animal y tenía un fin militar**, datan de 2008, y tuvo una gran evolución en los dos años siguientes gracias a la inyección de 32 millones de dólares por parte de Darpa, la agencia de proyectos más avanzados del departamento de Defensa estadounidense.

![Resultado de imagen de bigdog robot](https://img.vixdata.io/pd/jpg-large/es/sites/default/files/btg/curiosidades.batanga.com/files/lossy-page1-461px-Bio-inspired_Big_Dog_quadruped_robot_is_being_developed_as_a_mule_that_can_traverse_difficult_terrain.tiff_.jpg)



## Definiciones

Las definiciones siguientes no son de uso universal, pero proceden de un texto clásico sobre IA (Winston, 1984), así como del estudio de la inteligencia biológica (Barrows, 2000, atribuido a Romanes, 1883). La *inteligencia* es la capacidad de hacer lo correcto en el momento correcto, en un contexto en que no hacer nada (no cambiar de comportamiento) sería peor. Por lo tanto, la inteligencia requiere:

—capacidad de percibir *contextos* de acción,

—capacidad de *actuar* y

—capacidad de *asociar* determinados contextos a determinadas acciones.

De acuerdo con esta definición, las plantas son inteligentes (Trewavas, 2005), y también un termostato (McCarthy, 1983; Touretzky, 1988). Todos ellos pueden percibir el contexto y responder a él, por ejemplo, las plantas reaccionan a la dirección de la luz y los termostatos a la temperatura. A continuación clasificamos un sistema como *cognitivo* si es capaz de modificar su inteligencia, cosa que las plantas y los termostatos (al menos, los mecánicos) no pueden hacer. Los sistemas cognitivos pueden aprender nuevos contextos y acciones y/o asociaciones entre los primeros y las segundas. Ya estamos más cerca de la definición convencional de «inteligente».

La inteligencia, tal como definimos aquí, es un subconjunto estricto de la *computación*, es decir, de transformación de la información. Hay que tener en cuenta que la computación es un proceso físico, no matemático: requiere tiempo, espacio y energía. La inteligencia es el subconjunto de la computación que transforma un contexto en acción.

***Inteligencia artificial* (IA)**, por convención, es un término empleado para describir artefactos (normalmente digitales) que amplían alguna de las capacidades relacionadas con la inteligencia natural. Así, los sistemas automáticos de visión, el reconocimiento de voz, el reconocimiento de patrones y los sistemas de producción fija (es decir, que no aprenden) se consideran ejemplos de IA y sus algoritmos están explicados en los libros de texto sobre esta materia (Russell y Norvig, 2009). En todos los casos, también se pueden considerar formas de computación, aunque lo que produzcan no constituya una acción en un sentido convencional. Con todo, si aceptamos el concepto de robótica aplicada al cuerpo (ver más adelante), podríamos ampliar esta definición hasta considerar IA *cualquier* artefacto que amplíe nuestras capacidades de percepción y acción. Sería una definición inusual, pero nos facilitaría entender mejor la naturaleza de los cambios que la IA trae a nuestra sociedad, al permitirnos examinar un historial de intervenciones tecnológicas más dilatado.

El término *aprendizaje automático* (AA) designa cualquier medio de programación de IA que requiera no solo una codificación manual, también un componente de generalización automatizada de los datos presentados por medio de la acumulación de estadísticas sobre ellos (Murphy, 2012; Erickson *et al.*, 2017). A menudo, aunque no siempre, el AA se limita a buscar regularidades en los datos asociadas a categorías de interés, lo que incluye oportunidades apropiadas para determinadas acciones. Asimismo, el AA se usa con frecuencia para deducir asociaciones y también para adquirir nuevas competencias de acción; por ejemplo, a partir de la demostración (Huang *et al.*, 2016).

Debemos tener en cuenta que todo AA implica un componente programado manualmente. La mera conceptualización o descubrimiento de un algoritmo nunca conduce a la aparición espontánea de una máquina capaz de sentir o actuar. 

Los *robots* son artefactos que sienten y actúan en el mundo físico y en tiempo real. De acuerdo con esta definición, un teléfono inteligente es un robot (doméstico). Además de micrófonos, cuenta con varios tipos de sensores propioceptivos que le permiten saber cuándo su orientación está cambiando o desapareciendo. Su rango de tareas abarca la interacción con su usuario y la transmisión de información, instrucciones incluidas, a otros dispositivos. Lo mismo se puede decir de algunas consolas de videojuegos y de los asistentes digitales domésticos: los «altavoces inteligentes» o micrófonos, como Google Home; Echo, de Amazon (Alexa), o Cortana, de Microsoft.

![Resultado de imagen de alexa amazon google home y apple homepod](https://blogs.cdecomunicacion.es/borja-handfie/wp-content/uploads/sites/28/2018/12/google-home-amazon-echo-apple-homepod-1.jpg)



En términos técnicos, la *autonomía* es la capacidad de actuar como un individuo (Armstrong y Read, 1995; Cooke, 1999). Por ejemplo, un país pierde su autonomía bien si sus instituciones se desmoronan de manera que solo las acciones individuales de sus ciudadanos son eficaces, bien si sus instituciones están tan influidas por otros actores o gobiernos que no pueden determinar el rumbo del país por sí solas. Huelga decir que ambos extremos son muy inusuales. De hecho, entre animales sociales como los humanos, la autonomía nunca es absoluta (Gilbert *et al.*, 2012). Nuestra inteligencia individual determina muchas de nuestras acciones, pero algunas células pueden volverse cancerosas y atender a sus propios objetivos en detrimento de nuestro bienestar general (Hanahan y Weinberg, 2011). De un modo similar, entendemos que una familia, un lugar de trabajo o un gobierno influyan en nuestras acciones. También estamos sujetos a una influencia social muy superior de la que llegamos a ser conscientes (Devos y Banaji, 2003). Sin embargo se nos considera autónomos porque, en cierta medida, nuestra inteligencia individual también influye en nuestro comportamiento. Por consiguiente, un sistema técnico capaz de sentir el mundo y seleccionar una acción específica para el contexto en que se encuentre se denomina «autónomo» pese a que, en última instancia, sus acciones estén determinadas por los diseñadores que desarrollaron su inteligencia y los que lo operan. Los operarios pueden influir en la IA en directo y lo harán, de hecho, de antemano, al configurar los parámetros de su funcionamiento, lo que incluye cuándo y dónde funciona, si es que lo hace. Así pues, los diseñadores crean el sistema y determinan sus capacidades; en especial, a qué información puede acceder y qué acciones puede efectuar. E incluso si un diseñador decide introducir un componente de azar en sistema de IA, como la dependencia del entorno en que se encuentre o un generador de números aleatorios, dicha inclusión no deja de ser una elección deliberada.

## La IA en nuestra sociedad

En este 2019  **cada vez son más los productos o servicios que incluyen algún tipo de tecnología basada en IA**, desde los algoritmos del aprendizaje automático (machine learning) hasta las redes neuronales y el aprendizaje profundo.

La Inteligencia Artificial puede ofrecer una serie de **beneficios muy importantes en cualquier sector** y uso, ya que se trata de una de las tecnologías más transversales que existen en la actualidad. Cuando hacemos una **búsqueda en internet**, cuando hablamos con el smartphone o usamos **asistentes de voz** (Siri, Alexa o Google), abrimos una **cuenta bancaria**, cuando escribimos en un chatboot o cuando utilizamos, **en el** **trabajo**, un software de CRM estamos usando, en mayor o menor medida, inteligencia artificial.

Por ello, las grandes empresas van a invertir más en el desarrollo de esta tecnología, mientras que las más pequeñas ya la están incorporando en su día a día para **mejorar su eficiencia, reducir los costes y ser más competitivas**.

Los expertos en Inteligencia Artificial están trabajando en conseguir un **aprendizaje automático**, en ingeniería del conocimiento, visión artificial, procesamiento natural del lenguaje y minería de datos, con el fin de conseguir **soluciones realmente interesantes y útiles**.

### Campos de aplicación

#### **Medicina y Salud**

En la asistencia sanitaria el objetivo de la implementación de la inteligencia artificial pasa por **mejorar la atención a los pacientes y reducir los costes**. Para ello, las empresas están aplicando el aprendizaje de las máquinas para hacer mejores diagnósticos y más rápidos.

En este campo, una de las tecnologías sanitarias más conocidas es la de **IBM**, para la que ha desarrollado su unidad de negocio IBM Watson Health donde su sistema extrae datos de pacientes y de otras fuentes de datos disponibles para **formular una hipótesis**, que luego presenta con un esquema de **puntuación de confianza**.

Mencionar además un tema muy de actualidad como puede ser **el Coronavirus o Covid-19**. El virus nació en la región de Wuhan y en su seguimiento y evolución la ayuda de la Inteligencia Artificial ha sido de gran ayuda.

**¿Cómo se dio la voz de alarma de la epidemia en la región de Wuhan?** Un epidemiólogo chino informó a las autoridades en la víspera de la pasada Nochevieja y el Comité de Salud Municipal de Wuhan emitió el primer «aviso urgente por tratamiento de neumonía de causa desconocida».

El 9 de enero de 2020, se declararía la alerta sanitaria global por la Organización Mundial de la Salud (OMS) y los centros para el control y la prevención de enfermedades de EE.UU.

Pero, ¿cómo fue posible la celeridad y transparencia por parte del científico? Aquí es donde la tecnología ayudó. En concreto, mediante un sistema automático de vigilancia de enfermedades infecciosas del que hizo uso.

Este sistema fue capaz de leer un artículo escrito en mandarín en el que 27 personas sufrían de neumonía y todas ellas estaban conectadas de alguna forma con el mercado húmedo de Wuhan. Aunque el virus aún no estaba identificado, el algoritmo sí alertó de dos frases clave: “neumonía” y “causa desconocida”.

El sistema, creado por [BlueDot](https://bluedot.global/), una «startup» en Toronto nacida en 2014, **utilizó un algoritmo impulsado por IA que, mediante el procesamiento de lenguaje natural y aprendizaje automático, advirtió a sus clientes finales del más que probable brote de coronavirus**.

También las autoridades chinas están usando robots con inteligencia artificial en la lucha contra la epidemia del nuevo coronavirus (2019-nCoV), con el fin de reducir los riesgos de infecciones cruzadas y mejorar la eficiencia.

Por ejemplo, el hospital provincial de Guangdong, en el sur de China, tiene dos robots para entregar materiales en las áreas en cuarentena, según su director, Yu Xueqing. Mediante el uso de la tecnología de conducción no tripulada, los robots pueden identificar y leer mapas de forma independiente, planificar rutas y completar la distribución punto a punto.

Estos dispositivos han sido los principales responsables de entregar medicinas, comida, ropa y desechos médicos. En el proceso de entrega, no hay necesidad de personal, reduciendo así la frecuencia de entrada de sanitarios en las áreas en cuarentena.

#### **Negocios y empresas** 

La automatización de procesos robóticos se está aplicando a tareas altamente repetitivas que normalmente realizan los seres humanos. Gracias a los algoritmos de aprendizaje automático se intentan **descubrir información sobre cómo servir mejor a los clientes**. Un ejemplo son los chatbots, que se han incorporado en los sitios web para ofrecer un servicio inmediato a los clientes.

En el mundo de los negocios, según el último informe de GP Bullhound, se estima que casi una tercera parte de las compañías van a incorporar la inteligencia artificial en sus procesos a lo largo de este año, mientras que otro de Microsoft señala que **la mayoría de las empresas españolas cuenta con proyectos piloto de inteligencia artificial**, aunque sólo un 20% ha ido más allá de sus fases iniciales de pruebas de concepto. Así, cada vez habrán más aplicaciones en el ámbito del machine learning, que permite a los sistemas aprender sin que hayan sido específicamente programados para ello, y **habrá un incremento de la adopción Robotic Process Automation** (RPA), sistemas inteligentes que aprenden de aplicaciones ya existentes para procesar **transacciones, manipular datos y comunicarse con otros sistemas expertos**.

#### **Educación**

La IA permite evaluar a los estudiantes y adaptarse a sus necesidades, ayudándoles a trabajar a su propio ritmo. Los tutores pueden proporcionar apoyo adicional a los estudiantes, asegurando que se mantengan en el buen camino. De esta forma **podría cambiar dónde y cómo los estudiantes aprenden**, tal vez incluso reemplazando a algunos maestros.

#### **Finanzas**

 Hay aplicaciones que pueden recopilar datos personales y proporcionar asesoramiento financiero. Por ejemplo, hoy en día, el software realiza gran parte de las **operaciones en Wall Street**. En los bancos ya se utiliza para **evitar fraudes** o estudiar a los clientes.



#### Ámbito Jurídico 

El proceso de búsqueda y descubrimiento a través de la **revisión de documentos judiciales** es un trabajo abrumador para los seres humanos. Automatizar este proceso permite un mejor uso del tiempo y un proceso más eficiente.



#### Fabricación

 Ésta es un área que ha estado a la vanguardia de la incorporación de robots en el flujo de trabajo. Los robots industriales solían realizar tareas únicas y estaban separados de los trabajadores humanos, pero a medida que la tecnología avanza eso ha cambiado.



![img](https://www.diarioinformacion.com/elementosWeb/gestionCajas/INF/Image/2019//7-inteligencia-artificial-reconocimiento-facial-Microsoft-Google-asistentes--voz-Siri.jpg)



#### Predicción en las compras

 Amazon utiliza la IA para **anticipar** las necesidades de sus clientes.



#### **Generación de noticias** 

Varias compañías usan IA para escribir historias simples como resúmenes financieros o resúmenes de deportes. No se trata de artículos de fondo o piezas de periodismo de investigación, sino de **textos simples basados en datos duros**.



#### Motores de búsqueda

Google se vale de un sistema de inteligencia artificial para **interpretar consultas de búsqueda**, basándose en el posicionamiento geográfico, intereses y búsquedas previas.



![img](https://www.diarioinformacion.com/elementosWeb/gestionCajas/INF/Image/2019//8-inteligencia-artificial-reconocimiento-facial-Microsoft-Google-asistentes--voz-Siri.jpg)



#### **Reconocimiento facial biométrico** 

La biométrica es una aplicación de inteligencia artificial que aporta a los sistemas inteligentes la capacidad de recopilar datos sobre características faciales y demográficas. Así, las máquinas inteligentes pueden **adaptar sus respuestas analizando diferentes identidades** y respuestas emocionales.



#### **Agricultura**

 La utilización de drones para el campo junto con la IA pueden generar imágenes del campo con los colores de los diferentes cultivos, pudiendo identificarse plagas y buscar soluciones.

La implantación y el uso prometen ser **masivos en los próximos meses** gracias, además, al surgimiento de plataformas de inteligencia artificial en la **nube**, lo que está facilitando que haya una democratización de la IA al ponerla al alcance de empresas de menor tamaño. **Amazon , Google e IBM ya ofrecen sus propias plataformas**, de las que hablaremos más adelante.



### Plataformas existentes de Machine Learning

Entre las principales opciones que podemos encontrar son:

### **[Azure Machine Learning Studio](https://azure.microsoft.com/en-us/services/machine-learning-studio/)**

Esta opción de Microsoft cuenta con una interfaz de arrastrar y soltar que no requiere experiencia en codificación. Pero se necesita un enfoque aplicado al aprendizaje automático.

Permite integrar la tecnología en su trabajo rápidamente. La interfaz visual también permite exportar datos relacionados con el análisis predictivo. Por lo que es sencillo compartir sus hallazgos con los miembros de la junta ejecutiva u otros superiores.

Hay una versión gratuita disponible que le permite experimentar con el programa y cómo funciona. El precio [comienza en $ 9.99 por mes ](https://azure.microsoft.com/en-us/pricing/details/machine-learning-studio/).

### **[Amazon Machine Learning](https://aws.amazon.com/aml/)**

Este servicio de aprendizaje automático de Amazon presenta la misma tecnología utilizada internamente por sus científicos de datos. En este momento se encuentra disponible para los clientes que se suscriben al servicio.

Amazon es uno de los principales proveedores de MLaaS debido a que es altamente automatizado. Y es una opción ideal para los científicos de datos que necesitan confiar en el aprendizaje automático para cumplir con plazos ajustados.

La tecnología ofrece tres capacidades de predicción de aprendizaje automático. Con lo cual no es necesario conocer ningún método de aprendizaje automático antes de importar datos. La herramienta analiza la información y elige la mejor para usted.

Sin embargo la fijación de precios para la tecnología de Amazon no es tan sencilla como lo que Microsoft proporciona.

Por ejemplo detalles sobre el costo de análisis de datos y las tarifas de construcción del modelo más los precios [cobrados por las predicciones ](https://aws.amazon.com/aml/pricing/).

### **[Watson Machine Learning](https://www.datasciencecentral.com/profiles/blogs/machine-learning-as-a-service-mlaas)**

En marzo de 2018 IBM alojó Think 2018 que fue uno de los eventos tecnológicos más importantes de la historia. El programa de la conferencia dividió los eventos en varios campus.

Incluido uno llamado Business y AI que presentaba soluciones analíticas basadas en la nube. Sin dudas, los asistentes aprendieron sobre Watson Machine Learning de IBM allí.

Permite crear modelos de Machine learning con herramientas de aprendizaje automático visuales que ayudan a los usuarios a detectar patrones y tomar decisiones más inteligentes de lo que podrían sin esas ofertas.

Watson Machine Learning tiene un componente de aprendizaje profundo que incorpora redes neuronales.

Hay varias opciones bajo el paraguas de Watson Machine Learning. [Watson Studio ](https://www.ibm.com/cloud/watson-studio)permite usar herramientas de ciencia de datos de código abierto e interactuar con la información de arrastrar y soltar en los tableros.

Además de una versión gratuita hay [opciones premium a considerar ](https://www.ibm.com/cloud/machine-learning/pricing). También está el Catálogo de Conocimiento Watson, que ofrece conjuntos de datos y más para informar el trabajo de los científicos de datos.

### **[Google Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/)**

Mediante el uso de este producto podemos entrenar modelos de aprendizaje automático y luego usar la predicción en línea o la predicción por lotes para aplicar lo que el modelo aprendió a través del entrenamiento para hacerlo más inteligente.

Además no está restringido solo a los modelos de capacitación de máquinas de entrenamiento dentro del producto de Google. Acepta modelos entrenados en cualquier lugar.

Obtener [detalles de precios para su proyecto ](https://cloud.google.com/pricing/)solo es posible contactando a Google. Pero se informa que sus tarifas son sustancialmente menores que otros proveedores para algunos proyectos.

### **[BigML](https://bigml.com/)**

El deseo que motivó al equipo detrás de Big ML fue que [hiciera accesible el aprendizaje automático ](https://bigml.com/about)a todos. Entonces, si durante mucho tiempo ha estado interesado en aplicar el aprendizaje automático a su carrera de ciencia de datos, pero no estaba seguro de dónde comenzar entonces BigML podría ayudar.

Es como algunos de los otros servicios en esta lista en que la automatización juega un papel importante parte en cómo funciona el producto. Puede importar datos de múltiples fuentes y construir rápidamente modelos que se adapten a su flujo de trabajo. Incluso es posible insertar modelos en aplicaciones móviles y usarlos para hacer predicciones.

Hay un plan gratuito más [niveles premium a partir de $ 30 ](https://bigml.com/pricing#subscriptions).

### **[Dataiku](https://www.dataiku.com/)**

Dataiku ofrece a los usuarios las últimas bibliotecas de aprendizaje automático y permite a las personas usar R y Python para personalizar el código para ajustes avanzados.

La interfaz también proporciona comentarios sobre la importancia de diferentes variables. Luego puede comprender al instante qué características del programa Dataiku impactan más sus predicciones.

Además si es necesario volver a entrenar un modelo no necesita comenzar desde cero. Puede rastrear y guardar la progresión de la vida de un modelo y volver a una versión anterior con un clic.

Dataiku no publica detalles de fijación de precios en su sitio web porque las tasas varían según las necesidades. Sin embargo. Puede contactar al equipo de ventas para obtener más información después de decidir cómo el aprendizaje automático se ajusta mejor a sus requisitos de ciencia de datos.

De los que hemos hablado, en primer lugar nos centraremos principalmente en las plataformas que ofrecen Amazon, IBM y Google.

## Pruebas

### TensorFlow

![1200px-TensorFlowLogo.svg](https://i2.wp.com/puentesdigitales.com/wp-content/uploads/2018/02/1200px-tensorflowlogo-svg.png?resize=1200%2C1000&ssl=1)



TensorFlow es una **biblioteca de software de código abierto para computación numérica**, que utiliza gráficos de flujo de datos. Los nodos en las gráficas representan operaciones matemáticas, mientras que los bordes de las gráficas representan las matrices de datos multidimensionales (tensores) comunicadas entre ellos. Es una gran plataforma para **construir y entrenar redes neuronales**, que permiten detectar y descifrar patrones y correlaciones, análogos al aprendizaje y razonamiento usados por los humanos.

TensorFlow es una biblioteca de código abierto dirigida al aprendizaje automático a través de una serie de tareas. Ha sido desarrollado por Google para satisfacer las necesidades de sistemas capaces de **construir y entrenar redes neuronales para detectar y descifrar patrones y correlaciones, análogos al aprendizaje y razonamiento usados por los humanos** . Actualmente es utilizado tanto para la investigación como para la producción de productos de Google, remplazando el rol de su predecesor de código cerrado, DistBelief. Además fue originalmente desarrollado por el equipo de Google Brain para uso interno en Google antes de ser publicado bajo la licencia de código abierto Apache 2.0 el 9 de noviembre de 2015.

#### Algunos ejemplos de aplicación de TensorFlow

##### 1. Para mejorar la fotografía de los smartphones

Una de las aplicaciones más destacadas está en los teléfonos. Por ejemplo, el Pixel 2 que se lanzó este año, incluye efecto *bokeh* con una sola cámara. Se crea un modo retrato que separa a la persona del fondo, cuando esto era algo reservado para dispositivos con doble cámara. Y esto se consigue con el TensorFlow de Machine Learning, entrenando un modelo de TensorFlow en el backend, pero también ejecutándolo en el propio teléfono. No es tarea sencilla.

![girl-with-the-orange-hat-s.jpg](https://i2.wp.com/puentesdigitales.com/wp-content/uploads/2018/02/girl-with-the-orange-hat-s.jpg?resize=1540%2C1000&ssl=1)

Se trata un área muy interesante. Otras empresas necesitan múltiples cámaras para lograr básicamente el mismo resultado. La rapidez de la solución y el fantástico resultado que tiene es todo un hito tecnológico. Google ha sido capaz de imitar un efecto propio de la física óptica con sólo software y aprendizaje profundo.

##### 2. Para ayudar al diagnóstico médico

El sector de la salud es uno de los campos que más se están revolucionando y que mayor impacto tendrá para todos nosotros como sociedad en los próximos años.

TensorFlow ya está mejorando las herramientas que utilizan los médicos, por ejemplo ayudándoles a analizar radiografías. El Deep Learning va a permitir a los facultativos médicos pasar más tiempo con los pacientes, además de permitirles hacer actividades más interesantes y emocionantes.

![deep-learning-applications-in-medical-imaging-10.png](https://i1.wp.com/puentesdigitales.com/wp-content/uploads/2018/02/deep-learning-applications-in-medical-imaging-10.png?resize=828%2C315&ssl=1)

El Deep Learning podría estar en los dispositivos que llevan los médicos con ellos, por lo que definitivamente hay necesidad de que TensorFlow funcione en gran variedad de dispositivos.

##### 3. Procesamiento de imágenes

Una de las aplicaciones más conocidas de TensorFlow es el software automatizado de procesamiento de imágenes, [DeepDream](https://deepdreamgenerator.com/). Se trata de un programa de visión artificial creado por el ingeniero de Google Alexander Mordvintsev, que utiliza una red neuronal convolucional para encontrar y mejorar patrones en imágenes mediante pareidolia algorítmica, creando así una apariencia alucinógena, similar a un sueño, creando imágenes deliberadamente sobreprocesadas.

![3048941-poster-p-1-why-google-deep-dreams-of-dogs.jpg](https://i1.wp.com/puentesdigitales.com/wp-content/uploads/2018/02/3048941-poster-p-1-why-google-deep-dreams-of-dogs.jpg?resize=1280%2C720&ssl=1)

Google popularizó el término Deep Dreaming, simulando la idea de «sueño profundo». Curiosamente, también se ha demostrado que el modelo DeepDream tiene aplicación en el campo de la [historia del arte](https://edoc.hu-berlin.de/bitstream/handle/18452/19403/Spratt - final.pdf); algo de lo que hablaremos próximamente en otro artículo.

##### Flexibilidad y software libre

TensorFlow se construyó pensando en el código abierto y en la facilidad de ejecución y escalabilidad. Permite ser ejecutado en la nube, pero también en local. La idea es que cualquiera pueda ejecutarlo. Se puede ver a personas que lo ejecutan en una sola máquina, un único dispositivo, una sola CPU (o GPU) o en grandes clústeres. La disparidad es muy alta.

Y si realmente se desea escalar, la nube es un gran lugar para hacerlo. Se puede obtener mucha automatización. Google quiere asegurarse de que todo el mundo utilice TensorFlow, no necesariamente empujarlos hacia una u otra dirección.

![edge-computing-diagram-1024x512.png](https://i0.wp.com/puentesdigitales.com/wp-content/uploads/2018/02/edge-computing-diagram-1024x512.png?resize=1024%2C512&ssl=1)

##### El futuro de TensorFlow en el IoT

El Internet of Things (IoT) empieza a crecer y despegar. Hay un importante número de startups que están intentando crear lugares para la recolección de datos y que realmente están llevando el aprendizaje automático al límite. El IoT es un área muy interesante, pues desembocará en el [Edge Computing](https://puentesdigitales.com/2017/06/26/el-cloud-no-es-suficiente-para-el-iot-pasamos-de-la-nube-a-la-niebla/).

Por un lado, cuantos más datos y más heterogéneos e indefinidos, más interesante para el futuro del Deep Learning. Por otro lado, TensorFlow va enfocado a ejecutarse en distintos dispositivos y arquitecturas. Empresas como IBM o Atos tienen esta integración en el punto de mira.

TensorFlow seguirá dando que hablar. La comunidad de desarrolladores sigue aumentando y las librerías no paran de crecer y mejorar. Si quieres adentrarte de verdad en el mundo de la Inteligencia Artificial, TensorFlow es una plataforma básica para seguir avanzando.



##### Implementación

Para poder realizar una implementación con TensorFlow en nuestro script de Python, importamos las librerías a través de la siguiente línea.

```
import tensorflow as tf
```

Previamente instalando usando pip.

```bsh
# Requires the latest pip
pip install --upgrade pip

# Current stable release for CPU and GPU
pip install tensorflow

# Or try the preview build (unstable)
pip install tf-nightly
```



También tendremos que implementar **Keras**, Keras es un framework de alto nivel para el aprendizaje, escrito en **Python** y capaz de correr sobre los frameworks **TensorFlow**, **CNTK**, o **Theano**. Fue desarrollado con el objeto de facilitar un proceso de experimentación rápida. Lo que haremos en este experimento es entrenar modelos de clasificación de imágenes. Esto consiste en dada una serie de imágenes etiquetadas, reconocer una imagen y asignarle dicha etiqueta (por ejemplo, si es la foto de un gato, el modelo reconocerá que hay un gato).



En primer lugar lo instalaremos a través de pip:

*pip install keras*

Y a continuación importamos las librerías:

```
from tensorflow import keras
```



###### BIBLIOTECAS ADICIONALES

Otras bibliotecas adicionales que puede que se usen frecuentemente en nuestros proyectos de sistemas de aprendizaje son:

- pathlib: para la gestión de rutas de ficheros.
- numpy: Biblioteca matemática.
- scypi: Biblioteca matemática.
- pandas: Análisis de datos y estadística
- matplotlib: Creación de gráficas
- seaborn: Graficas estadísticas



En nuestro proyecto quizás nos interesa más instalar pandas, para ello ejecutamos y lo importamos al mismo tiempo:

*pip install pandas* ------------------------------------------------------------------------------------------------------ *import pandas*



En primer lugar se nos presenta el fallo de a continuación:

![image-20200319093617396](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200319093617396.png)



Para solucionarlo tenemos que cambiar de versión, tener en cuenta que las versiones variarán en función de las versiones de Python:

*pip install tensorflow==2.0*
*pip install --upgrade tensorflow-gpu==2.0*



Una vez arreglado el problema de las versiones podremos continuar intentando implementar el uso correcto de tensorflow en nuestro caso.

En primer lugar utilizaremos el [tutorial](https://www.tensorflow.org/tutorials/load_data/text) que ofrece tensorflow para cargar los txt, que nos interesa utilizar como los datos a entrenar y verificar, en nuestro caso, disponemos de en torno a unos poco mas de 60 de pdfs, por tanto utilizaremos unos 30 para el entrenamiento y los 30 para verficiar la correcta clasificación.

Antes de seguir hemos de mencionar que los datos que se utilizan en el tutorial se encuentran ubicados dentro de TensorFlow Datasets, que se puede definir como una colección de conjuntos de datos listos para usar, con TensorFlow u otros marcos de Python ML, como Jax. Todos los conjuntos de datos se exponen como tf.data.Datasets, lo que permite canalizaciones de entrada fáciles de usar y de alto rendimiento.0

Entrando en https://www.tensorflow.org/datasets/add_dataset podemos investigar como añadir nuestro propios datos de la manera correcta, además como se puede ver se nos presenta diversas opciones como partir del repositorio [tensorflow/datasets](https://github.com/tensorflow/datasets/blob/master/CONTRIBUTING.md) podemos contribuir y compartir nuestros datos en el caso de que fueran útiles para la comunidad, o añadir nuestros datos sin necesidad de contribuir a los repositorios [tfds](https://www.tensorflow.org/datasets/api_docs/python/tfds).

Como ya hemos mencionado en numerosos casos, nuestros pdfs tienen numerosos datos que no pueden ser compartidos ya que presentan numerosos datos que pueden identificar a personas, entidades o empresas con gran facilidad y que por tanto deben ser protegidos. Por tanto elaboraremos nuestro propio conjunto de datos fuera de los repositorios tfds.

Como podemos ver en los dos enlaces anteriores de tutoriales con diferentes explicaciones, todos los datos utilizados se encuentran publicados 

##### ¿Qué necesito para dar de alta un modelo tensorflow en Google Cloud?

Con las herramientas que ofrece Google Cloud, entre las que destacamos  [Compute Engine](https://cloud.google.com/compute/?hl=es) y Machine Learning Engine, podemos entrenar, monitorizar y explotar modelos. En primer lugar tendremos que seguir los siguientes pasos para realizar la configuración:

1- Crearemos el proyecto que llevará el nombre de Tensorflow, siguiendo los pasos que se nos explican en el enlace de: https://cloud.google.com/resource-manager/docs/creating-managing-projects

![image-20200408092020441](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200408092020441.png)

2- Habilitaremos la API de Google Cloud Platform que nos permite crear modelos de aprendizaje.

![image-20200408092644923](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200408092644923.png)

3- Instalación del **[Software Development Kit](https://dl.google.com/dl/cloudsdk/channels/rapid/GoogleCloudSDKInstaller.exe)** de Google (SDK):  se puede definir como un conjunto de herramientas que nos permite acceder a los productos y servicios de Google Cloud desde linea de comandos. Tenemos que tener cuidado ya que requiere la versión de Python 2.7.9 o versiones posteriores. 

![image-20200408093346648](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200408093346648.png)



Se nos presenta fallos en la instalacion de los SDK.

![image-20200408100119661](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200408100119661.png)

- **NOTA:** Hemos de introducir para que funcione correctamente la instalación de los SDK, en las variables de entorno tanto del sistema como las del usuario.

  Una vez lo hemos añadido en las variables podemos ejecutar las siguientes intrucciones que aparecen en este enlace: https://cloud.google.com/sdk/docs/downloads-interactive?hl=es-419#windows
  
  ![image-20200408140236857](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200408140236857.png)

Una de las dudas que se nos presenta es si los datos han de estar subidos en el storage de Google Cloud

### IBM Watson Machine Learning

En primer lugar comenzaremos utilizando la plataforma de IBM, para ello hemos de registrarnos en primer lugar en la plataforma, donde nada mas entrar nos encontraremos ante este panel de control que vemos a continuación.

![image-20200311121839296](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311121839296.png)



Si accedemos a las diferentes opciones que ofrece el panel de control.

![image-20200311123917680](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311123917680.png)

Bajamos hasta Watson que es la que nos ofrece el uso de inteligencia artificial.

![image-20200311124041668](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311124041668.png)



Dentro de Watson buscaremos , el que se llama Machine Learning. Tenemos que decir que cuando sacamos la información de los PDFs a través de nuestro proyecto, buscamos sacar del pdf la información que pueda clasificarnos el texto en los distintos departamentos o procedimientos que componen la autoridad portuaria de en este caso de Santa Cruz de Tenerife.

![image-20200311125304683](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311125304683.png)

Por ello los datos personales de personas o empresas, como pueden ser DNIs, nombres comerciales de empresa, nombres y apellidos de personas o números de identificación de una solicitud, reclamación o de cualquier documento en cuestión, buscaremos en un caso ideal, pero que por ahora no es del nuestro proyecto, evitar enviarselos a la IA, ya que buscaremos reservar esta información en una base de datos con toda esta información. Así como también evitaremos enviar el lenguaje natural, que debería ser desechado sin ningún problema.

Una vez nos creamos un recurso de machine learning

![image-20200311131457241](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311131457241.png)

A continuación creamos unas credenciales de servicio para probar como funciona la IA de IBM, establecemos unas credenciales como administrador y otro como escritor.

![image-20200311132619182](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311132619182.png)



![image-20200311132541394](C:\Users\erik_\AppData\Roaming\Typora\typora-user-images\image-20200311132541394.png)

